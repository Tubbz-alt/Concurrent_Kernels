To fully exploit the computational power of the GPU generally a large amount of data parallelism must be expressed. If your problem does not possess a <a href="https://www.olcf.ornl.gov/support/system-user-guides/accelerated-computing-guide/#3093">sufficient</a> amount of data parallelism a second option is to combine data parallelism with task parallelism on the GPU through the use of concurrent kernels. To facilitate task parallelism the NVIDIA Kepler K20x features <code>Hyper-Q</code>, a set of 32 hardware managed work queues. When using CUDA streams each stream will be automatically mapped onto <code>Hyper-Q</code>, allowing up to 32 streams to execute concurrency. The NVIDIA </code>Multi-Process Service</code> allows multiple processes, such as intra-node MPI ranks, to be mapped onto <code>Hyper-Q</code>. This tutorial will demonstrate how to take advantage of GPU concurrency on Titan through the use of <code>Hyper-Q</code>. The full source can be viewed or downloaded from the <a href=https://github.com/olcf/Concurrent-Kernels>OLCF GitHub</a>. Please direct any questions or comments to <a href="mailto:help@nccs.gov">help@nccs.gov</a>
